{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1649957428444,
     "user": {
      "displayName": "Sam Lu",
      "userId": "15789059763790170725"
     },
     "user_tz": -480
    },
    "id": "WGYnB9z5GEne"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from collections import namedtuple\n",
    "import itertools\n",
    "from itertools import count\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np\n",
    "import collections\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1649957428445,
     "user": {
      "displayName": "Sam Lu",
      "userId": "15789059763790170725"
     },
     "user_tz": -480
    },
    "id": "z8M3b0CiGEnj"
   },
   "outputs": [],
   "source": [
    "class PolicyNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, action_bound):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc_mu = torch.nn.Linear(hidden_dim, action_dim)\n",
    "        self.fc_std = torch.nn.Linear(hidden_dim, action_dim)\n",
    "        self.action_bound = action_bound\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        mu = self.fc_mu(x)\n",
    "        std = F.softplus(self.fc_std(x))\n",
    "        dist = Normal(mu, std)\n",
    "        normal_sample = dist.rsample()  # rsample()是重参数化采样函数\n",
    "        log_prob = dist.log_prob(normal_sample)\n",
    "        action = torch.tanh(normal_sample)  # 计算tanh_normal分布的对数概率密度\n",
    "        log_prob = log_prob - torch.log(1 - torch.tanh(action).pow(2) + 1e-7)\n",
    "        action = action * self.action_bound\n",
    "        return action, log_prob\n",
    "\n",
    "\n",
    "class QValueNet(torch.nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim):\n",
    "        super(QValueNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(state_dim + action_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        cat = torch.cat([x, a], dim=1)  # 拼接状态和动作\n",
    "        x = F.relu(self.fc1(cat))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\n",
    "    \"cpu\")\n",
    "\n",
    "\n",
    "class SAC:\n",
    "    ''' 处理连续动作的SAC算法 '''\n",
    "    def __init__(self, state_dim, hidden_dim, action_dim, action_bound,\n",
    "                 actor_lr, critic_lr, alpha_lr, target_entropy, tau, gamma):\n",
    "        self.actor = PolicyNet(state_dim, hidden_dim, action_dim,\n",
    "                               action_bound).to(device)  # 策略网络\n",
    "        # 第一个Q网络\n",
    "        self.critic_1 = QValueNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        # 第二个Q网络\n",
    "        self.critic_2 = QValueNet(state_dim, hidden_dim, action_dim).to(device)\n",
    "        self.target_critic_1 = QValueNet(state_dim, hidden_dim,\n",
    "                                         action_dim).to(device)  # 第一个目标Q网络\n",
    "        self.target_critic_2 = QValueNet(state_dim, hidden_dim,\n",
    "                                         action_dim).to(device)  # 第二个目标Q网络\n",
    "        # 令目标Q网络的初始参数和Q网络一样\n",
    "        self.target_critic_1.load_state_dict(self.critic_1.state_dict())\n",
    "        self.target_critic_2.load_state_dict(self.critic_2.state_dict())\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),\n",
    "                                                lr=actor_lr)\n",
    "        self.critic_1_optimizer = torch.optim.Adam(self.critic_1.parameters(),\n",
    "                                                   lr=critic_lr)\n",
    "        self.critic_2_optimizer = torch.optim.Adam(self.critic_2.parameters(),\n",
    "                                                   lr=critic_lr)\n",
    "        # 使用alpha的log值,可以使训练结果比较稳定\n",
    "        self.log_alpha = torch.tensor(np.log(0.01), dtype=torch.float)\n",
    "        self.log_alpha.requires_grad = True  # 可以对alpha求梯度\n",
    "        self.log_alpha_optimizer = torch.optim.Adam([self.log_alpha],\n",
    "                                                    lr=alpha_lr)\n",
    "        self.target_entropy = target_entropy  # 目标熵的大小\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "\n",
    "    def take_action(self, state):\n",
    "        state = torch.tensor([state], dtype=torch.float).to(device)\n",
    "        action = self.actor(state)[0]\n",
    "        return [action.item()]\n",
    "\n",
    "    def calc_target(self, rewards, next_states, dones):  # 计算目标Q值\n",
    "        next_actions, log_prob = self.actor(next_states)\n",
    "        entropy = -log_prob\n",
    "        q1_value = self.target_critic_1(next_states, next_actions)\n",
    "        q2_value = self.target_critic_2(next_states, next_actions)\n",
    "        next_value = torch.min(q1_value,\n",
    "                               q2_value) + self.log_alpha.exp() * entropy\n",
    "        td_target = rewards + self.gamma * next_value * (1 - dones)\n",
    "        return td_target\n",
    "\n",
    "    def soft_update(self, net, target_net):\n",
    "        for param_target, param in zip(target_net.parameters(),\n",
    "                                       net.parameters()):\n",
    "            param_target.data.copy_(param_target.data * (1.0 - self.tau) +\n",
    "                                    param.data * self.tau)\n",
    "\n",
    "    def update(self, transition_dict):\n",
    "        states = torch.tensor(transition_dict['states'],\n",
    "                              dtype=torch.float).to(device)\n",
    "        actions = torch.tensor(transition_dict['actions'],\n",
    "                               dtype=torch.float).view(-1, 1).to(device)\n",
    "        rewards = torch.tensor(transition_dict['rewards'],\n",
    "                               dtype=torch.float).view(-1, 1).to(device)\n",
    "        next_states = torch.tensor(transition_dict['next_states'],\n",
    "                                   dtype=torch.float).to(device)\n",
    "        dones = torch.tensor(transition_dict['dones'],\n",
    "                             dtype=torch.float).view(-1, 1).to(device)\n",
    "        rewards = (rewards + 8.0) / 8.0  # 对倒立摆环境的奖励进行重塑\n",
    "\n",
    "        # 更新两个Q网络\n",
    "        td_target = self.calc_target(rewards, next_states, dones)\n",
    "        critic_1_loss = torch.mean(\n",
    "            F.mse_loss(self.critic_1(states, actions), td_target.detach()))\n",
    "        critic_2_loss = torch.mean(\n",
    "            F.mse_loss(self.critic_2(states, actions), td_target.detach()))\n",
    "        self.critic_1_optimizer.zero_grad()\n",
    "        critic_1_loss.backward()\n",
    "        self.critic_1_optimizer.step()\n",
    "        self.critic_2_optimizer.zero_grad()\n",
    "        critic_2_loss.backward()\n",
    "        self.critic_2_optimizer.step()\n",
    "\n",
    "        # 更新策略网络\n",
    "        new_actions, log_prob = self.actor(states)\n",
    "        entropy = -log_prob\n",
    "        q1_value = self.critic_1(states, new_actions)\n",
    "        q2_value = self.critic_2(states, new_actions)\n",
    "        actor_loss = torch.mean(-self.log_alpha.exp() * entropy -\n",
    "                                torch.min(q1_value, q2_value))\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # 更新alpha值\n",
    "        alpha_loss = torch.mean(\n",
    "            (entropy - target_entropy).detach() * self.log_alpha.exp())\n",
    "        self.log_alpha_optimizer.zero_grad()\n",
    "        alpha_loss.backward()\n",
    "        self.log_alpha_optimizer.step()\n",
    "\n",
    "        self.soft_update(self.critic_1, self.target_critic_1)\n",
    "        self.soft_update(self.critic_2, self.target_critic_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1649957428446,
     "user": {
      "displayName": "Sam Lu",
      "userId": "15789059763790170725"
     },
     "user_tz": -480
    },
    "id": "xfK4N1doGEnl"
   },
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    ''' Swish激活函数 '''\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    ''' 初始化模型权重 '''\n",
    "    def truncated_normal_init(t, mean=0.0, std=0.01):\n",
    "        torch.nn.init.normal_(t, mean=mean, std=std)\n",
    "        while True:\n",
    "            cond = (t < mean - 2 * std) | (t > mean + 2 * std)\n",
    "            if not torch.sum(cond):\n",
    "                break\n",
    "            t = torch.where(\n",
    "                cond,\n",
    "                torch.nn.init.normal_(torch.ones(t.shape, device=device),\n",
    "                                      mean=mean,\n",
    "                                      std=std), t)\n",
    "        return t\n",
    "\n",
    "    if type(m) == nn.Linear or isinstance(m, FCLayer):\n",
    "        truncated_normal_init(m.weight, std=1 / (2 * np.sqrt(m._input_dim)))\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "class FCLayer(nn.Module):\n",
    "    ''' 集成之后的全连接层 '''\n",
    "    def __init__(self, input_dim, output_dim, ensemble_size, activation):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self._input_dim, self._output_dim = input_dim, output_dim\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.Tensor(ensemble_size, input_dim, output_dim).to(device))\n",
    "        self._activation = activation\n",
    "        self.bias = nn.Parameter(\n",
    "            torch.Tensor(ensemble_size, output_dim).to(device))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._activation(\n",
    "            torch.add(torch.bmm(x, self.weight), self.bias[:, None, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1649957441286,
     "user": {
      "displayName": "Sam Lu",
      "userId": "15789059763790170725"
     },
     "user_tz": -480
    },
    "id": "o8OfdjXJGEnm"
   },
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    ''' 环境模型集成 '''\n",
    "    def __init__(self,\n",
    "                 state_dim,\n",
    "                 action_dim,\n",
    "                 model_alpha,\n",
    "                 ensemble_size=5,\n",
    "                 learning_rate=1e-3):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        # 输出包括均值和方差,因此是状态与奖励维度之和的两倍\n",
    "        self._output_dim = (state_dim + 1) * 2\n",
    "        self._model_alpha = model_alpha  # 模型损失函数中加权时的权重\n",
    "        self._max_logvar = nn.Parameter((torch.ones(\n",
    "            (1, self._output_dim // 2)).float() / 2).to(device),\n",
    "                                        requires_grad=False)\n",
    "        self._min_logvar = nn.Parameter((-torch.ones(\n",
    "            (1, self._output_dim // 2)).float() * 10).to(device),\n",
    "                                        requires_grad=False)\n",
    "\n",
    "        self.layer1 = FCLayer(state_dim + action_dim, 200, ensemble_size,\n",
    "                              Swish())\n",
    "        self.layer2 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer3 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer4 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer5 = FCLayer(200, self._output_dim, ensemble_size,\n",
    "                              nn.Identity())\n",
    "        self.apply(init_weights)  # 初始化环境模型中的参数\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x, return_log_var=False):\n",
    "        ret = self.layer5(self.layer4(self.layer3(self.layer2(\n",
    "            self.layer1(x)))))\n",
    "        mean = ret[:, :, :self._output_dim // 2]\n",
    "        # 在PETS算法中,将方差控制在最小值和最大值之间\n",
    "        logvar = self._max_logvar - F.softplus(\n",
    "            self._max_logvar - ret[:, :, self._output_dim // 2:])\n",
    "        logvar = self._min_logvar + F.softplus(logvar - self._min_logvar)\n",
    "        return mean, logvar if return_log_var else torch.exp(logvar)\n",
    "\n",
    "    def loss(self, mean, logvar, labels, use_var_loss=True):\n",
    "        inverse_var = torch.exp(-logvar)\n",
    "        if use_var_loss:\n",
    "            mse_loss = torch.mean(torch.mean(torch.pow(mean - labels, 2) *\n",
    "                                             inverse_var,\n",
    "                                             dim=-1),\n",
    "                                  dim=-1)\n",
    "            var_loss = torch.mean(torch.mean(logvar, dim=-1), dim=-1)\n",
    "            total_loss = torch.sum(mse_loss) + torch.sum(var_loss)\n",
    "        else:\n",
    "            mse_loss = torch.mean(torch.pow(mean - labels, 2), dim=(1, 2))\n",
    "            total_loss = torch.sum(mse_loss)\n",
    "        return total_loss, mse_loss\n",
    "\n",
    "    def train(self, loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss += self._model_alpha * torch.sum(\n",
    "            self._max_logvar) - self._model_alpha * torch.sum(self._min_logvar)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "\n",
    "class EnsembleDynamicsModel:\n",
    "    ''' 环境模型集成,加入精细化的训练 '''\n",
    "    def __init__(self, state_dim, action_dim, model_alpha=0.01, num_network=5):\n",
    "        self._num_network = num_network\n",
    "        self._state_dim, self._action_dim = state_dim, action_dim\n",
    "        self.model = EnsembleModel(state_dim,\n",
    "                                   action_dim,\n",
    "                                   model_alpha,\n",
    "                                   ensemble_size=num_network)\n",
    "        self._epoch_since_last_update = 0\n",
    "\n",
    "    def train(self,\n",
    "              inputs,\n",
    "              labels,\n",
    "              batch_size=64,\n",
    "              holdout_ratio=0.1,\n",
    "              max_iter=20):\n",
    "        # 设置训练集与验证集\n",
    "        permutation = np.random.permutation(inputs.shape[0])\n",
    "        inputs, labels = inputs[permutation], labels[permutation]\n",
    "        num_holdout = int(inputs.shape[0] * holdout_ratio)\n",
    "        train_inputs, train_labels = inputs[num_holdout:], labels[num_holdout:]\n",
    "        holdout_inputs, holdout_labels = inputs[:\n",
    "                                                num_holdout], labels[:\n",
    "                                                                     num_holdout]\n",
    "        holdout_inputs = torch.from_numpy(holdout_inputs).float().to(device)\n",
    "        holdout_labels = torch.from_numpy(holdout_labels).float().to(device)\n",
    "        holdout_inputs = holdout_inputs[None, :, :].repeat(\n",
    "            [self._num_network, 1, 1])\n",
    "        holdout_labels = holdout_labels[None, :, :].repeat(\n",
    "            [self._num_network, 1, 1])\n",
    "\n",
    "        # 保留最好的结果\n",
    "        self._snapshots = {i: (None, 1e10) for i in range(self._num_network)}\n",
    "\n",
    "        for epoch in itertools.count():\n",
    "            # 定义每一个网络的训练数据\n",
    "            train_index = np.vstack([\n",
    "                np.random.permutation(train_inputs.shape[0])\n",
    "                for _ in range(self._num_network)\n",
    "            ])\n",
    "            # 所有真实数据都用来训练\n",
    "            for batch_start_pos in range(0, train_inputs.shape[0], batch_size):\n",
    "                batch_index = train_index[:, batch_start_pos:batch_start_pos +\n",
    "                                          batch_size]\n",
    "                train_input = torch.from_numpy(\n",
    "                    train_inputs[batch_index]).float().to(device)\n",
    "                train_label = torch.from_numpy(\n",
    "                    train_labels[batch_index]).float().to(device)\n",
    "\n",
    "                mean, logvar = self.model(train_input, return_log_var=True)\n",
    "                loss, _ = self.model.loss(mean, logvar, train_label)\n",
    "                self.model.train(loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                mean, logvar = self.model(holdout_inputs, return_log_var=True)\n",
    "                _, holdout_losses = self.model.loss(mean,\n",
    "                                                    logvar,\n",
    "                                                    holdout_labels,\n",
    "                                                    use_var_loss=False)\n",
    "                holdout_losses = holdout_losses.cpu()\n",
    "                break_condition = self._save_best(epoch, holdout_losses)\n",
    "                if break_condition or epoch > max_iter:  # 结束训练\n",
    "                    break\n",
    "\n",
    "    def _save_best(self, epoch, losses, threshold=0.1):\n",
    "        updated = False\n",
    "        for i in range(len(losses)):\n",
    "            current = losses[i]\n",
    "            _, best = self._snapshots[i]\n",
    "            improvement = (best - current) / best\n",
    "            if improvement > threshold:\n",
    "                self._snapshots[i] = (epoch, current)\n",
    "                updated = True\n",
    "        self._epoch_since_last_update = 0 if updated else self._epoch_since_last_update + 1\n",
    "        return self._epoch_since_last_update > 5\n",
    "\n",
    "    def predict(self, inputs, batch_size=64):\n",
    "        inputs = np.tile(inputs, (self._num_network, 1, 1))\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float).to(device)\n",
    "        mean, var = self.model(inputs, return_log_var=False)\n",
    "        return mean.detach().cpu().numpy(), var.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "class FakeEnv:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def step(self, obs, act):\n",
    "        inputs = np.concatenate((obs, act), axis=-1)\n",
    "        ensemble_model_means, ensemble_model_vars = self.model.predict(inputs)\n",
    "        ensemble_model_means[:, :, 1:] += obs\n",
    "        ensemble_model_stds = np.sqrt(ensemble_model_vars)\n",
    "        ensemble_samples = ensemble_model_means + np.random.normal(\n",
    "            size=ensemble_model_means.shape) * ensemble_model_stds\n",
    "\n",
    "        num_models, batch_size, _ = ensemble_model_means.shape\n",
    "        models_to_use = np.random.choice(\n",
    "            [i for i in range(self.model._num_network)], size=batch_size)\n",
    "        batch_inds = np.arange(0, batch_size)\n",
    "        samples = ensemble_samples[models_to_use, batch_inds]\n",
    "        rewards, next_obs = samples[:, :1][0][0], samples[:, 1:][0]\n",
    "        return rewards, next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1649957452282,
     "user": {
      "displayName": "Sam Lu",
      "userId": "15789059763790170725"
     },
     "user_tz": -480
    },
    "id": "T1X6ABP3GEno"
   },
   "outputs": [],
   "source": [
    "class MBPO:\n",
    "    def __init__(self, env, agent, fake_env, env_pool, model_pool,\n",
    "                 rollout_length, rollout_batch_size, real_ratio, num_episode):\n",
    "\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.fake_env = fake_env\n",
    "        self.env_pool = env_pool\n",
    "        self.model_pool = model_pool\n",
    "        self.rollout_length = rollout_length\n",
    "        self.rollout_batch_size = rollout_batch_size\n",
    "        self.real_ratio = real_ratio\n",
    "        self.num_episode = num_episode\n",
    "\n",
    "    def rollout_model(self):\n",
    "        observations, _, _, _, _ = self.env_pool.sample(\n",
    "            self.rollout_batch_size)\n",
    "        for obs in observations:\n",
    "            for i in range(self.rollout_length):\n",
    "                action = self.agent.take_action(obs)\n",
    "                reward, next_obs = self.fake_env.step(obs, action)\n",
    "                self.model_pool.add(obs, action, reward, next_obs, False)\n",
    "                obs = next_obs\n",
    "\n",
    "    def update_agent(self, policy_train_batch_size=64):\n",
    "        env_batch_size = int(policy_train_batch_size * self.real_ratio)\n",
    "        model_batch_size = policy_train_batch_size - env_batch_size\n",
    "        for epoch in range(10):\n",
    "            env_obs, env_action, env_reward, env_next_obs, env_done = self.env_pool.sample(\n",
    "                env_batch_size)\n",
    "            if self.model_pool.size() > 0:\n",
    "                model_obs, model_action, model_reward, model_next_obs, model_done = self.model_pool.sample(\n",
    "                    model_batch_size)\n",
    "                obs = np.concatenate((env_obs, model_obs), axis=0)\n",
    "                action = np.concatenate((env_action, model_action), axis=0)\n",
    "                next_obs = np.concatenate((env_next_obs, model_next_obs),\n",
    "                                          axis=0)\n",
    "                reward = np.concatenate((env_reward, model_reward), axis=0)\n",
    "                done = np.concatenate((env_done, model_done), axis=0)\n",
    "            else:\n",
    "                obs, action, next_obs, reward, done = env_obs, env_action, env_next_obs, env_reward, env_done\n",
    "            transition_dict = {\n",
    "                'states': obs,\n",
    "                'actions': action,\n",
    "                'next_states': next_obs,\n",
    "                'rewards': reward,\n",
    "                'dones': done\n",
    "            }\n",
    "            self.agent.update(transition_dict)\n",
    "\n",
    "    def train_model(self):\n",
    "        obs, action, reward, next_obs, done = self.env_pool.return_all_samples(\n",
    "        )\n",
    "        inputs = np.concatenate((obs, action), axis=-1)\n",
    "        reward = np.array(reward)\n",
    "        labels = np.concatenate(\n",
    "            (np.reshape(reward, (reward.shape[0], -1)), next_obs - obs),\n",
    "            axis=-1)\n",
    "        self.fake_env.model.train(inputs, labels)\n",
    "\n",
    "    def explore(self):\n",
    "        obs, done, episode_return = self.env.reset(), False, 0\n",
    "        while not done:\n",
    "            action = self.agent.take_action(obs)\n",
    "            next_obs, reward, done, _ = self.env.step(action)\n",
    "            self.env_pool.add(obs, action, reward, next_obs, done)\n",
    "            obs = next_obs\n",
    "            episode_return += reward\n",
    "        return episode_return\n",
    "\n",
    "    def train(self):\n",
    "        return_list = []\n",
    "        explore_return = self.explore()  # 随机探索采取数据\n",
    "        print('episode: 1, return: %d' % explore_return)\n",
    "        return_list.append(explore_return)\n",
    "\n",
    "        for i_episode in range(self.num_episode - 1):\n",
    "            obs, done, episode_return = self.env.reset(), False, 0\n",
    "            step = 0\n",
    "            while not done:\n",
    "                if step % 50 == 0:\n",
    "                    self.train_model()\n",
    "                    self.rollout_model()\n",
    "                action = self.agent.take_action(obs)\n",
    "                next_obs, reward, done, _ = self.env.step(action)\n",
    "                self.env_pool.add(obs, action, reward, next_obs, done)\n",
    "                obs = next_obs\n",
    "                episode_return += reward\n",
    "\n",
    "                self.update_agent()\n",
    "                step += 1\n",
    "            return_list.append(episode_return)\n",
    "            print('episode: %d, return: %d' % (i_episode + 2, episode_return))\n",
    "        return return_list\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if batch_size > len(self.buffer):\n",
    "            return self.return_all_samples()\n",
    "        else:\n",
    "            transitions = random.sample(self.buffer, batch_size)\n",
    "            state, action, reward, next_state, done = zip(*transitions)\n",
    "            return np.array(state), action, reward, np.array(next_state), done\n",
    "\n",
    "    def return_all_samples(self):\n",
    "        all_transitions = list(self.buffer)\n",
    "        state, action, reward, next_state, done = zip(*all_transitions)\n",
    "        return np.array(state), action, reward, np.array(next_state), done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "executionInfo": {
     "elapsed": 613836,
     "status": "ok",
     "timestamp": 1649958070782,
     "user": {
      "displayName": "Sam Lu",
      "userId": "15789059763790170725"
     },
     "user_tz": -480
    },
    "id": "_gcY5HvTGEnr",
    "outputId": "49c828a2-35ec-44d9-f952-a52e01e46fe8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billmlion/miniconda3/envs/RLws/lib/python3.9/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/Users/billmlion/miniconda3/envs/RLws/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/var/folders/ns/snlbpbln0w9fk_x7wpkkdxyh0000gn/T/ipykernel_19763/3606784039.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:277.)\n",
      "  state = torch.tensor([state], dtype=torch.float).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1, return: -1642\n",
      "episode: 2, return: -1400\n",
      "episode: 3, return: -1405\n",
      "episode: 4, return: -1536\n",
      "episode: 5, return: -1658\n",
      "episode: 6, return: -1135\n",
      "episode: 7, return: -1017\n",
      "episode: 8, return: -817\n",
      "episode: 9, return: -251\n",
      "episode: 10, return: -250\n",
      "episode: 11, return: -246\n",
      "episode: 12, return: -1\n",
      "episode: 13, return: -236\n",
      "episode: 14, return: -123\n",
      "episode: 15, return: -223\n",
      "episode: 16, return: -118\n",
      "episode: 17, return: -117\n",
      "episode: 18, return: -125\n",
      "episode: 19, return: -132\n",
      "episode: 20, return: -117\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "real_ratio = 0.5\n",
    "env_name = 'Pendulum-v1'\n",
    "env = gym.make(env_name)\n",
    "num_episodes = 20\n",
    "actor_lr = 5e-4\n",
    "critic_lr = 5e-3\n",
    "alpha_lr = 1e-3\n",
    "hidden_dim = 128\n",
    "gamma = 0.98\n",
    "tau = 0.005  # 软更新参数\n",
    "buffer_size = 10000\n",
    "target_entropy = -1\n",
    "model_alpha = 0.01  # 模型损失函数中的加权权重\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "action_bound = env.action_space.high[0]  # 动作最大值\n",
    "\n",
    "rollout_batch_size = 1000\n",
    "rollout_length = 1  # 推演长度k,推荐更多尝试\n",
    "model_pool_size = rollout_batch_size * rollout_length\n",
    "\n",
    "agent = SAC(state_dim, hidden_dim, action_dim, action_bound, actor_lr,\n",
    "            critic_lr, alpha_lr, target_entropy, tau, gamma)\n",
    "model = EnsembleDynamicsModel(state_dim, action_dim, model_alpha)\n",
    "fake_env = FakeEnv(model)\n",
    "env_pool = ReplayBuffer(buffer_size)\n",
    "model_pool = ReplayBuffer(model_pool_size)\n",
    "mbpo = MBPO(env, agent, fake_env, env_pool, model_pool, rollout_length,\n",
    "            rollout_batch_size, real_ratio, num_episodes)\n",
    "\n",
    "return_list = mbpo.train()\n",
    "\n",
    "episodes_list = list(range(len(return_list)))\n",
    "plt.plot(episodes_list, return_list)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('MBPO on {}'.format(env_name))\n",
    "plt.show()\n",
    "\n",
    "# episode: 1, return: -1083\n",
    "# episode: 2, return: -1324\n",
    "# episode: 3, return: -979\n",
    "# episode: 4, return: -130\n",
    "# episode: 5, return: -246\n",
    "# episode: 6, return: -2\n",
    "# episode: 7, return: -239\n",
    "# episode: 8, return: -2\n",
    "# episode: 9, return: -122\n",
    "# episode: 10, return: -236\n",
    "# episode: 11, return: -238\n",
    "# episode: 12, return: -2\n",
    "# episode: 13, return: -127\n",
    "# episode: 14, return: -128\n",
    "# episode: 15, return: -125\n",
    "# episode: 16, return: -124\n",
    "# episode: 17, return: -125\n",
    "# episode: 18, return: -247\n",
    "# episode: 19, return: -127\n",
    "# episode: 20, return: -129"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "第17章-基于模型的策略优化.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "RLws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
